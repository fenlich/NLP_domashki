{
  "cells": [
    {
      "cell_type": "markdown",
      "id": "1dba7c0d",
      "metadata": {
        "id": "1dba7c0d"
      },
      "source": [
        "# Домашнее задание № 10. Машинный перевод"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "Yj7aripVIsbG",
      "metadata": {
        "id": "Yj7aripVIsbG"
      },
      "source": [
        "## Задание 1 (6 баллов + 2 доп балла).\n",
        "Нужно обучить трансформер на том же корпусе но в другую сторону - с русского на английский.\n",
        "Можно использовать как основу первый или второй способ реализации (с MultiheadAttention или с nn.Transformer). Подберите несколько тестовых примеров для проверки обучения на каждой эпохе.\n",
        "\n",
        "Параметры ниже точно работают в колабе и модель обучается достаточно быстро. Попробуйте их немного увеличить (batch size возможно придется наоборот уменьшить). Обучайте модель хотя бы 5 эпох, а желательно больше, чтобы тестовые примеры начали переводиться более менее адекватно.\n",
        "\n",
        "После обучения возьмите хотя бы 100 примером из тестовой части параллельного корпуса и переведите их. Оцените качество переводов с помощью метрики BLEU (пример использования ниже)\n",
        "Найдите лучшие (как минимум 5) переводы согласно этой метрике и проверьте действительно ли они хорошие. Если все переводы нулевые, то пообучайте модель подольше.\n",
        "\n",
        "Чтобы получить 2 доп балла вам нужно будет придумать как оптимизировать функцию translate. Сейчас она работает только с одним текстом - это не эффективно. Можно генерировать переводы сразу для нескольких текстов (батча). Главная сложность с таким подходом состоит в том, что генерируемые тексты будут заканчиваться в разное время и нужно сделать столько итераций, сколько нужно для завершения всех текстов (т.е. условие на то, что последний токен не равен [EOS] в текущем коде не сработает).\n",
        "ВАЖНО - недостаточно просто изменить входной аргумент с text на texts и добавить еще один цикл по texts! Сама модель должна вызываться на нескольких текстах! Функция с batch prediction должна работать быстрее, поэтому переведите всю тестовую выборку и оцените качество BLEU на всех данных."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "05d202c4",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 1000
        },
        "id": "05d202c4",
        "outputId": "5d5177ef-946b-4cea-96dd-041358c193ec"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting torchtune\n",
            "  Downloading torchtune-0.6.1-py3-none-any.whl.metadata (24 kB)\n",
            "Collecting torchao\n",
            "  Downloading torchao-0.10.0-cp39-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl.metadata (15 kB)\n",
            "Collecting torchdata==0.11.0 (from torchtune)\n",
            "  Downloading torchdata-0.11.0-py3-none-any.whl.metadata (6.3 kB)\n",
            "Collecting datasets (from torchtune)\n",
            "  Downloading datasets-3.5.0-py3-none-any.whl.metadata (19 kB)\n",
            "Requirement already satisfied: huggingface_hub[hf_transfer] in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.30.1)\n",
            "Requirement already satisfied: safetensors in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.5.3)\n",
            "Requirement already satisfied: kagglehub in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.3.11)\n",
            "Requirement already satisfied: sentencepiece in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.2.0)\n",
            "Collecting tiktoken (from torchtune)\n",
            "  Downloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (6.7 kB)\n",
            "Collecting blobfile>=2 (from torchtune)\n",
            "  Downloading blobfile-3.0.0-py3-none-any.whl.metadata (15 kB)\n",
            "Requirement already satisfied: tokenizers in /usr/local/lib/python3.11/dist-packages (from torchtune) (0.21.1)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.11/dist-packages (from torchtune) (2.0.2)\n",
            "Requirement already satisfied: tqdm in /usr/local/lib/python3.11/dist-packages (from torchtune) (4.67.1)\n",
            "Collecting omegaconf (from torchtune)\n",
            "  Downloading omegaconf-2.3.0-py3-none-any.whl.metadata (3.9 kB)\n",
            "Requirement already satisfied: psutil in /usr/local/lib/python3.11/dist-packages (from torchtune) (5.9.5)\n",
            "Requirement already satisfied: Pillow>=9.4.0 in /usr/local/lib/python3.11/dist-packages (from torchtune) (11.1.0)\n",
            "Requirement already satisfied: urllib3>=1.25 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.11.0->torchtune) (2.3.0)\n",
            "Requirement already satisfied: requests in /usr/local/lib/python3.11/dist-packages (from torchdata==0.11.0->torchtune) (2.32.3)\n",
            "Requirement already satisfied: torch>=2 in /usr/local/lib/python3.11/dist-packages (from torchdata==0.11.0->torchtune) (2.6.0+cu124)\n",
            "Collecting pycryptodomex>=3.8 (from blobfile>=2->torchtune)\n",
            "  Downloading pycryptodomex-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (3.4 kB)\n",
            "Requirement already satisfied: lxml>=4.9 in /usr/local/lib/python3.11/dist-packages (from blobfile>=2->torchtune) (5.3.1)\n",
            "Requirement already satisfied: filelock>=3.0 in /usr/local/lib/python3.11/dist-packages (from blobfile>=2->torchtune) (3.18.0)\n",
            "Requirement already satisfied: pyarrow>=15.0.0 in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (18.1.0)\n",
            "Collecting dill<0.3.9,>=0.3.0 (from datasets->torchtune)\n",
            "  Downloading dill-0.3.8-py3-none-any.whl.metadata (10 kB)\n",
            "Requirement already satisfied: pandas in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (2.2.2)\n",
            "Collecting xxhash (from datasets->torchtune)\n",
            "  Downloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (12 kB)\n",
            "Collecting multiprocess<0.70.17 (from datasets->torchtune)\n",
            "  Downloading multiprocess-0.70.16-py311-none-any.whl.metadata (7.2 kB)\n",
            "Collecting fsspec<=2024.12.0,>=2023.1.0 (from fsspec[http]<=2024.12.0,>=2023.1.0->datasets->torchtune)\n",
            "  Downloading fsspec-2024.12.0-py3-none-any.whl.metadata (11 kB)\n",
            "Requirement already satisfied: aiohttp in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (3.11.15)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (24.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.11/dist-packages (from datasets->torchtune) (6.0.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4.3 in /usr/local/lib/python3.11/dist-packages (from huggingface_hub[hf_transfer]->torchtune) (4.13.1)\n",
            "Collecting hf-transfer>=0.1.4 (from huggingface_hub[hf_transfer]->torchtune)\n",
            "  Downloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl.metadata (1.7 kB)\n",
            "Collecting antlr4-python3-runtime==4.9.* (from omegaconf->torchtune)\n",
            "  Downloading antlr4-python3-runtime-4.9.3.tar.gz (117 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m117.0/117.0 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h  Preparing metadata (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "Requirement already satisfied: regex>=2022.1.18 in /usr/local/lib/python3.11/dist-packages (from tiktoken->torchtune) (2024.11.6)\n",
            "Requirement already satisfied: aiohappyeyeballs>=2.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (2.6.1)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (1.3.2)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (25.3.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (1.5.0)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (6.3.2)\n",
            "Requirement already satisfied: propcache>=0.2.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (0.3.1)\n",
            "Requirement already satisfied: yarl<2.0,>=1.17.0 in /usr/local/lib/python3.11/dist-packages (from aiohttp->datasets->torchtune) (1.18.3)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata==0.11.0->torchtune) (3.4.1)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata==0.11.0->torchtune) (3.10)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.11/dist-packages (from requests->torchdata==0.11.0->torchtune) (2025.1.31)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (3.1.6)\n",
            "Collecting nvidia-cuda-nvrtc-cu12==12.4.127 (from torch>=2->torchdata==0.11.0->torchtune)\n",
            "  Downloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-runtime-cu12==12.4.127 (from torch>=2->torchdata==0.11.0->torchtune)\n",
            "  Downloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cuda-cupti-cu12==12.4.127 (from torch>=2->torchdata==0.11.0->torchtune)\n",
            "  Downloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cudnn-cu12==9.1.0.70 (from torch>=2->torchdata==0.11.0->torchtune)\n",
            "  Downloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cublas-cu12==12.4.5.8 (from torch>=2->torchdata==0.11.0->torchtune)\n",
            "  Downloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cufft-cu12==11.2.1.3 (from torch>=2->torchdata==0.11.0->torchtune)\n",
            "  Downloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-curand-cu12==10.3.5.147 (from torch>=2->torchdata==0.11.0->torchtune)\n",
            "  Downloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Collecting nvidia-cusolver-cu12==11.6.1.9 (from torch>=2->torchdata==0.11.0->torchtune)\n",
            "  Downloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Collecting nvidia-cusparse-cu12==12.3.1.170 (from torch>=2->torchdata==0.11.0->torchtune)\n",
            "  Downloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl.metadata (1.6 kB)\n",
            "Requirement already satisfied: nvidia-cusparselt-cu12==0.6.2 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (0.6.2)\n",
            "Requirement already satisfied: nvidia-nccl-cu12==2.21.5 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (2.21.5)\n",
            "Requirement already satisfied: nvidia-nvtx-cu12==12.4.127 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (12.4.127)\n",
            "Collecting nvidia-nvjitlink-cu12==12.4.127 (from torch>=2->torchdata==0.11.0->torchtune)\n",
            "  Downloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl.metadata (1.5 kB)\n",
            "Requirement already satisfied: triton==3.2.0 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (3.2.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.11/dist-packages (from torch>=2->torchdata==0.11.0->torchtune) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.11/dist-packages (from sympy==1.13.1->torch>=2->torchdata==0.11.0->torchtune) (1.3.0)\n",
            "Requirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->torchtune) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->torchtune) (2025.2)\n",
            "Requirement already satisfied: tzdata>=2022.7 in /usr/local/lib/python3.11/dist-packages (from pandas->datasets->torchtune) (2025.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.11/dist-packages (from python-dateutil>=2.8.2->pandas->datasets->torchtune) (1.17.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.11/dist-packages (from jinja2->torch>=2->torchdata==0.11.0->torchtune) (3.0.2)\n",
            "Downloading torchtune-0.6.1-py3-none-any.whl (910 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m910.7/910.7 kB\u001b[0m \u001b[31m27.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchdata-0.11.0-py3-none-any.whl (61 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.0/62.0 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading torchao-0.10.0-cp39-abi3-manylinux_2_24_x86_64.manylinux_2_28_x86_64.whl (5.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m5.5/5.5 MB\u001b[0m \u001b[31m28.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading blobfile-3.0.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.4/75.4 kB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading datasets-3.5.0-py3-none-any.whl (491 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m491.2/491.2 kB\u001b[0m \u001b[31m23.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading omegaconf-2.3.0-py3-none-any.whl (79 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m79.5/79.5 kB\u001b[0m \u001b[31m7.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading tiktoken-0.9.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.2 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.2/1.2 MB\u001b[0m \u001b[31m38.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading dill-0.3.8-py3-none-any.whl (116 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m116.3/116.3 kB\u001b[0m \u001b[31m10.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading fsspec-2024.12.0-py3-none-any.whl (183 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m183.9/183.9 kB\u001b[0m \u001b[31m14.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading hf_transfer-0.1.9-cp38-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (3.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m3.6/3.6 MB\u001b[0m \u001b[31m44.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading multiprocess-0.70.16-py311-none-any.whl (143 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m143.5/143.5 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading pycryptodomex-3.22.0-cp37-abi3-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (2.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.3/2.3 MB\u001b[0m \u001b[31m31.2 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cublas_cu12-12.4.5.8-py3-none-manylinux2014_x86_64.whl (363.4 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m363.4/363.4 MB\u001b[0m \u001b[31m3.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_cupti_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (13.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m13.8/13.8 MB\u001b[0m \u001b[31m114.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_nvrtc_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (24.6 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m24.6/24.6 MB\u001b[0m \u001b[31m87.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cuda_runtime_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (883 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m883.7/883.7 kB\u001b[0m \u001b[31m59.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cudnn_cu12-9.1.0.70-py3-none-manylinux2014_x86_64.whl (664.8 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.8/664.8 MB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cufft_cu12-11.2.1.3-py3-none-manylinux2014_x86_64.whl (211.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m211.5/211.5 MB\u001b[0m \u001b[31m5.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_curand_cu12-10.3.5.147-py3-none-manylinux2014_x86_64.whl (56.3 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m56.3/56.3 MB\u001b[0m \u001b[31m16.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusolver_cu12-11.6.1.9-py3-none-manylinux2014_x86_64.whl (127.9 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m127.9/127.9 MB\u001b[0m \u001b[31m7.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_cusparse_cu12-12.3.1.170-py3-none-manylinux2014_x86_64.whl (207.5 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.5/207.5 MB\u001b[0m \u001b[31m5.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading nvidia_nvjitlink_cu12-12.4.127-py3-none-manylinux2014_x86_64.whl (21.1 MB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m21.1/21.1 MB\u001b[0m \u001b[31m88.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hDownloading xxhash-3.5.0-cp311-cp311-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (194 kB)\n",
            "\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m194.8/194.8 kB\u001b[0m \u001b[31m18.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hBuilding wheels for collected packages: antlr4-python3-runtime\n",
            "  Building wheel for antlr4-python3-runtime (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for antlr4-python3-runtime: filename=antlr4_python3_runtime-4.9.3-py3-none-any.whl size=144554 sha256=b577ddcb3ff02ca6618659ad1d1bb3ce30f5b7b617988934292a7d9a09d99566\n",
            "  Stored in directory: /root/.cache/pip/wheels/1a/97/32/461f837398029ad76911109f07047fde1d7b661a147c7c56d1\n",
            "Successfully built antlr4-python3-runtime\n",
            "Installing collected packages: torchao, antlr4-python3-runtime, xxhash, pycryptodomex, omegaconf, nvidia-nvjitlink-cu12, nvidia-curand-cu12, nvidia-cufft-cu12, nvidia-cuda-runtime-cu12, nvidia-cuda-nvrtc-cu12, nvidia-cuda-cupti-cu12, nvidia-cublas-cu12, hf-transfer, fsspec, dill, tiktoken, nvidia-cusparse-cu12, nvidia-cudnn-cu12, multiprocess, blobfile, nvidia-cusolver-cu12, datasets, torchdata, torchtune\n",
            "  Attempting uninstall: nvidia-nvjitlink-cu12\n",
            "    Found existing installation: nvidia-nvjitlink-cu12 12.5.82\n",
            "    Uninstalling nvidia-nvjitlink-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-nvjitlink-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-curand-cu12\n",
            "    Found existing installation: nvidia-curand-cu12 10.3.6.82\n",
            "    Uninstalling nvidia-curand-cu12-10.3.6.82:\n",
            "      Successfully uninstalled nvidia-curand-cu12-10.3.6.82\n",
            "  Attempting uninstall: nvidia-cufft-cu12\n",
            "    Found existing installation: nvidia-cufft-cu12 11.2.3.61\n",
            "    Uninstalling nvidia-cufft-cu12-11.2.3.61:\n",
            "      Successfully uninstalled nvidia-cufft-cu12-11.2.3.61\n",
            "  Attempting uninstall: nvidia-cuda-runtime-cu12\n",
            "    Found existing installation: nvidia-cuda-runtime-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-runtime-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-runtime-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-nvrtc-cu12\n",
            "    Found existing installation: nvidia-cuda-nvrtc-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-nvrtc-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-nvrtc-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cuda-cupti-cu12\n",
            "    Found existing installation: nvidia-cuda-cupti-cu12 12.5.82\n",
            "    Uninstalling nvidia-cuda-cupti-cu12-12.5.82:\n",
            "      Successfully uninstalled nvidia-cuda-cupti-cu12-12.5.82\n",
            "  Attempting uninstall: nvidia-cublas-cu12\n",
            "    Found existing installation: nvidia-cublas-cu12 12.5.3.2\n",
            "    Uninstalling nvidia-cublas-cu12-12.5.3.2:\n",
            "      Successfully uninstalled nvidia-cublas-cu12-12.5.3.2\n",
            "  Attempting uninstall: fsspec\n",
            "    Found existing installation: fsspec 2025.3.2\n",
            "    Uninstalling fsspec-2025.3.2:\n",
            "      Successfully uninstalled fsspec-2025.3.2\n",
            "  Attempting uninstall: nvidia-cusparse-cu12\n",
            "    Found existing installation: nvidia-cusparse-cu12 12.5.1.3\n",
            "    Uninstalling nvidia-cusparse-cu12-12.5.1.3:\n",
            "      Successfully uninstalled nvidia-cusparse-cu12-12.5.1.3\n",
            "  Attempting uninstall: nvidia-cudnn-cu12\n",
            "    Found existing installation: nvidia-cudnn-cu12 9.3.0.75\n",
            "    Uninstalling nvidia-cudnn-cu12-9.3.0.75:\n",
            "      Successfully uninstalled nvidia-cudnn-cu12-9.3.0.75\n",
            "  Attempting uninstall: nvidia-cusolver-cu12\n",
            "    Found existing installation: nvidia-cusolver-cu12 11.6.3.83\n",
            "    Uninstalling nvidia-cusolver-cu12-11.6.3.83:\n",
            "      Successfully uninstalled nvidia-cusolver-cu12-11.6.3.83\n",
            "\u001b[31mERROR: pip's dependency resolver does not currently take into account all the packages that are installed. This behaviour is the source of the following dependency conflicts.\n",
            "gcsfs 2025.3.2 requires fsspec==2025.3.2, but you have fsspec 2024.12.0 which is incompatible.\u001b[0m\u001b[31m\n",
            "\u001b[0mSuccessfully installed antlr4-python3-runtime-4.9.3 blobfile-3.0.0 datasets-3.5.0 dill-0.3.8 fsspec-2024.12.0 hf-transfer-0.1.9 multiprocess-0.70.16 nvidia-cublas-cu12-12.4.5.8 nvidia-cuda-cupti-cu12-12.4.127 nvidia-cuda-nvrtc-cu12-12.4.127 nvidia-cuda-runtime-cu12-12.4.127 nvidia-cudnn-cu12-9.1.0.70 nvidia-cufft-cu12-11.2.1.3 nvidia-curand-cu12-10.3.5.147 nvidia-cusolver-cu12-11.6.1.9 nvidia-cusparse-cu12-12.3.1.170 nvidia-nvjitlink-cu12-12.4.127 omegaconf-2.3.0 pycryptodomex-3.22.0 tiktoken-0.9.0 torchao-0.10.0 torchdata-0.11.0 torchtune-0.6.1 xxhash-3.5.0\n"
          ]
        },
        {
          "output_type": "display_data",
          "data": {
            "application/vnd.colab-display-data+json": {
              "pip_warning": {
                "packages": [
                  "pydevd_plugins"
                ]
              },
              "id": "a151687f344f4211bda127c4cc1dd79a"
            }
          },
          "metadata": {}
        }
      ],
      "source": [
        "# В колабе установите torchtune и torchao, чтобы семинарская тетрадка работала\n",
        "!pip install torchtune torchao"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "id": "fc8bf45f",
      "metadata": {
        "id": "fc8bf45f"
      },
      "outputs": [],
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "import torch.optim as optim\n",
        "import torch.utils.data\n",
        "\n",
        "from tokenizers import Tokenizer\n",
        "from tokenizers.models import BPE\n",
        "from tokenizers.pre_tokenizers import Whitespace\n",
        "from tokenizers.trainers import BpeTrainer\n",
        "from tokenizers import decoders\n",
        "\n",
        "import os\n",
        "import numpy as np\n",
        "from sklearn.model_selection import StratifiedShuffleSplit, train_test_split\n",
        "from collections import Counter\n",
        "\n",
        "from torchtune.modules import RotaryPositionalEmbeddings\n",
        "from torch.nn import Transformer\n",
        "import matplotlib.pyplot as plt\n",
        "%matplotlib inline"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "id": "81832c7e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "81832c7e",
        "outputId": "fbaf69ec-a384-494c-94b9-f4b273b1fd98"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "--2025-04-13 11:55:00--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.ru\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.32.28\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.32.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 121340806 (116M)\n",
            "Saving to: ‘opus.en-ru-train.ru.1’\n",
            "\n",
            "opus.en-ru-train.ru 100%[===================>] 115.72M  24.5MB/s    in 5.8s    \n",
            "\n",
            "2025-04-13 11:55:07 (19.8 MB/s) - ‘opus.en-ru-train.ru.1’ saved [121340806/121340806]\n",
            "\n",
            "--2025-04-13 11:55:07--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.en\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.32.28\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.32.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 67760131 (65M)\n",
            "Saving to: ‘opus.en-ru-train.en.1’\n",
            "\n",
            "opus.en-ru-train.en 100%[===================>]  64.62M  19.9MB/s    in 3.9s    \n",
            "\n",
            "2025-04-13 11:55:11 (16.7 MB/s) - ‘opus.en-ru-train.en.1’ saved [67760131/67760131]\n",
            "\n",
            "--2025-04-13 11:55:11--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.ru\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.32.28\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.32.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 305669 (299K)\n",
            "Saving to: ‘opus.en-ru-test.ru.1’\n",
            "\n",
            "opus.en-ru-test.ru. 100%[===================>] 298.50K   410KB/s    in 0.7s    \n",
            "\n",
            "2025-04-13 11:55:13 (410 KB/s) - ‘opus.en-ru-test.ru.1’ saved [305669/305669]\n",
            "\n",
            "--2025-04-13 11:55:13--  https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.en\n",
            "Resolving data.statmt.org (data.statmt.org)... 129.215.32.28\n",
            "Connecting to data.statmt.org (data.statmt.org)|129.215.32.28|:443... connected.\n",
            "HTTP request sent, awaiting response... 200 OK\n",
            "Length: 173307 (169K)\n",
            "Saving to: ‘opus.en-ru-test.en.1’\n",
            "\n",
            "opus.en-ru-test.en. 100%[===================>] 169.25K   354KB/s    in 0.5s    \n",
            "\n",
            "2025-04-13 11:55:14 (354 KB/s) - ‘opus.en-ru-test.en.1’ saved [173307/173307]\n",
            "\n"
          ]
        }
      ],
      "source": [
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.ru\n",
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-train.en\n",
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.ru\n",
        "!wget https://data.statmt.org/opus-100-corpus/v1.0/supervised/en-ru/opus.en-ru-test.en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "id": "e20035a9",
      "metadata": {
        "id": "e20035a9"
      },
      "outputs": [],
      "source": [
        "text = open('opus.en-ru-train.ru').read().replace('\\xa0', ' ')\n",
        "f = open('opus.en-ru-train.ru', 'w')\n",
        "f.write(text)\n",
        "f.close()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "id": "f94ebe0f",
      "metadata": {
        "id": "f94ebe0f"
      },
      "outputs": [],
      "source": [
        "en_sents = open('opus.en-ru-train.en').read().splitlines()\n",
        "ru_sents = open('opus.en-ru-train.ru').read().splitlines()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "id": "be55d6f2",
      "metadata": {
        "id": "be55d6f2"
      },
      "outputs": [],
      "source": [
        "tokenizer_ru = Tokenizer(BPE())\n",
        "tokenizer_ru.pre_tokenizer = Whitespace()\n",
        "# в encoder нам не нужно обозначать начало и конец поэтому единственный доп токен это паддинг\n",
        "trainer_ru = BpeTrainer(special_tokens=[\"[PAD]\"], end_of_word_suffix='</w>')\n",
        "tokenizer_ru.train(files=[\"opus.en-ru-train.ru\"], trainer=trainer_ru)\n",
        "\n",
        "tokenizer_en = Tokenizer(BPE())\n",
        "tokenizer_en.pre_tokenizer = Whitespace()\n",
        "# в декодере добавим теги начала и конца для корректной генерации\n",
        "trainer_en = BpeTrainer(special_tokens=[\"[PAD]\", \"[BOS]\", \"[EOS]\"], end_of_word_suffix='</w>')\n",
        "tokenizer_en.train(files=[\"opus.en-ru-train.en\"], trainer=trainer_en)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "id": "0cbfafe7",
      "metadata": {
        "id": "0cbfafe7"
      },
      "outputs": [],
      "source": [
        "tokenizer_en.decoder = decoders.BPEDecoder()\n",
        "tokenizer_ru.decoder = decoders.BPEDecoder()"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer_en.save('tokenizer_en')\n",
        "tokenizer_ru.save('tokenizer_ru')"
      ],
      "metadata": {
        "id": "_WiNTfL08Sl_"
      },
      "id": "_WiNTfL08Sl_",
      "execution_count": 7,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": 8,
      "id": "8ca1bd76",
      "metadata": {
        "id": "8ca1bd76"
      },
      "outputs": [],
      "source": [
        "tokenizer_en = Tokenizer.from_file(\"tokenizer_en\")\n",
        "tokenizer_ru = Tokenizer.from_file(\"tokenizer_ru\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 9,
      "id": "e5253cc8",
      "metadata": {
        "id": "e5253cc8"
      },
      "outputs": [],
      "source": [
        "def encode(text, tokenizer, max_len, encoder=False):\n",
        "    if encoder:\n",
        "        return tokenizer.encode(text).ids[:max_len]\n",
        "    else:\n",
        "        return [tokenizer.token_to_id('[BOS]')] + tokenizer.encode(text).ids[:max_len] + [tokenizer.token_to_id('[EOS]')]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 10,
      "id": "6f0bf6a3",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6f0bf6a3",
        "outputId": "2241fd26-e348-41a0-c0df-74019c07f4f9"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0"
            ]
          },
          "metadata": {},
          "execution_count": 10
        }
      ],
      "source": [
        "PAD_IDX = tokenizer_ru.token_to_id('[PAD]')\n",
        "PAD_IDX"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 11,
      "id": "57bfc41a",
      "metadata": {
        "id": "57bfc41a"
      },
      "outputs": [],
      "source": [
        "max_len_en, max_len_ru = 47, 48"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 12,
      "id": "17bdfc4a",
      "metadata": {
        "id": "17bdfc4a"
      },
      "outputs": [],
      "source": [
        "X_en = [encode(t, tokenizer_en, max_len_en) for t in en_sents]\n",
        "X_ru = [encode(t, tokenizer_ru, max_len_ru, encoder=True) for t in ru_sents]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "id": "861aa104",
      "metadata": {
        "id": "861aa104"
      },
      "outputs": [],
      "source": [
        "class Dataset(torch.utils.data.Dataset):\n",
        "\n",
        "    def __init__(self, texts_ru, texts_en):\n",
        "        self.texts_en = [torch.LongTensor(sent) for sent in texts_en]\n",
        "        self.texts_en = torch.nn.utils.rnn.pad_sequence(self.texts_en, batch_first=True, padding_value=PAD_IDX)\n",
        "\n",
        "        self.texts_ru = [torch.LongTensor(sent) for sent in texts_ru]\n",
        "        self.texts_ru = torch.nn.utils.rnn.pad_sequence(self.texts_ru, batch_first=True, padding_value=PAD_IDX)\n",
        "\n",
        "        self.length = len(texts_ru)\n",
        "\n",
        "    def __len__(self):\n",
        "        return self.length\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "\n",
        "        ids_en = self.texts_en[index]\n",
        "        ids_ru = self.texts_ru[index]\n",
        "\n",
        "        return ids_ru, ids_en"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "id": "6b521936",
      "metadata": {
        "id": "6b521936"
      },
      "outputs": [],
      "source": [
        "X_ru_train, X_ru_valid, X_en_train, X_en_valid, = train_test_split(X_ru, X_en, test_size=0.05)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "id": "24116418",
      "metadata": {
        "id": "24116418"
      },
      "outputs": [],
      "source": [
        "from time import time\n",
        "def train(model, iterator, optimizer, criterion, scheduler, run=None, print_every=100):\n",
        "\n",
        "    epoch_loss = []\n",
        "    ac = []\n",
        "\n",
        "    model.train()\n",
        "\n",
        "    for i, (texts_ru, texts_en) in enumerate(iterator):\n",
        "        texts_en = texts_en.to(DEVICE)\n",
        "        texts_ru = texts_ru.to(DEVICE)\n",
        "        texts_en_input = texts_en[:,:-1].to(DEVICE)\n",
        "        texts_en_out = texts_en[:, 1:].to(DEVICE)\n",
        "        src_padding_mask = (texts_ru == PAD_IDX).to(DEVICE)\n",
        "        tgt_padding_mask = (texts_en_input == PAD_IDX).to(DEVICE)\n",
        "        logits = model(texts_ru, texts_en_input, src_padding_mask, tgt_padding_mask)\n",
        "        optimizer.zero_grad()\n",
        "        B,S,C = logits.shape\n",
        "        loss = loss_fn(logits.reshape(B*S, C), texts_en_out.reshape(B*S))\n",
        "        loss.backward()\n",
        "        optimizer.step()\n",
        "        scheduler.step()\n",
        "        epoch_loss.append(loss.item())\n",
        "\n",
        "        if not (i+1) % print_every:\n",
        "            print(f'Loss: {np.mean(epoch_loss)};')\n",
        "        if run is not None:\n",
        "            run.log({\"loss\": loss.item()})\n",
        "\n",
        "    return np.mean(epoch_loss)\n",
        "\n",
        "\n",
        "def evaluate(model, iterator, criterion, run=None):\n",
        "\n",
        "    epoch_loss = []\n",
        "    epoch_f1 = []\n",
        "\n",
        "    model.eval()\n",
        "    with torch.no_grad():\n",
        "        for i, (texts_ru, texts_en) in enumerate(iterator):\n",
        "            texts_en = texts_en.to(DEVICE)\n",
        "            texts_ru = texts_ru.to(DEVICE)\n",
        "            texts_en_input = texts_en[:,:-1].to(DEVICE)\n",
        "            texts_en_out = texts_en[:, 1:].to(DEVICE)\n",
        "            src_padding_mask = (texts_ru == PAD_IDX).to(DEVICE)\n",
        "            tgt_padding_mask = (texts_en_input == PAD_IDX).to(DEVICE)\n",
        "\n",
        "            logits = model(texts_ru, texts_en_input, src_padding_mask, tgt_padding_mask)\n",
        "\n",
        "            B,S,C = logits.shape\n",
        "            loss = loss_fn(logits.reshape(B*S, C), texts_en_out.reshape(B*S))\n",
        "            epoch_loss.append(loss.item())\n",
        "            if run is not None:\n",
        "                run.log({\"val_loss\": loss.item()})\n",
        "\n",
        "    return np.mean(epoch_loss)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "id": "c6f89bcd",
      "metadata": {
        "id": "c6f89bcd"
      },
      "outputs": [],
      "source": [
        "@torch.no_grad\n",
        "def translate(text):\n",
        "\n",
        "    input_ids = tokenizer_ru.encode(text).ids[:max_len_ru]\n",
        "    output_ids = [tokenizer_en.token_to_id('[BOS]')]\n",
        "\n",
        "    input_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(input_ids)], batch_first=True).to(DEVICE)\n",
        "    output_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(output_ids)], batch_first=True).to(DEVICE)\n",
        "\n",
        "    src_padding_mask = (input_ids_pad == PAD_IDX).to(DEVICE)\n",
        "    tgt_padding_mask = (output_ids_pad == PAD_IDX).to(DEVICE)\n",
        "\n",
        "    logits = model(input_ids_pad, output_ids_pad, src_padding_mask, tgt_padding_mask)\n",
        "\n",
        "    pred = logits.argmax(2).item()\n",
        "\n",
        "    while pred not in [tokenizer_en.token_to_id('[EOS]'), tokenizer_en.token_to_id('[PAD]')] and len(output_ids) < 100:\n",
        "        output_ids.append(pred)\n",
        "        output_ids_pad = torch.nn.utils.rnn.pad_sequence([torch.LongTensor(output_ids)], batch_first=True).to(DEVICE)\n",
        "        tgt_padding_mask = (output_ids_pad == PAD_IDX).to(DEVICE)\n",
        "\n",
        "        logits = model(input_ids_pad, output_ids_pad, src_padding_mask, tgt_padding_mask)\n",
        "        pred = logits.argmax(2).view(-1)[-1].item()\n",
        "\n",
        "    return tokenizer_en.decoder.decode([tokenizer_en.id_to_token(i) for i in output_ids[1:]])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 27,
      "id": "f6008a8a",
      "metadata": {
        "id": "f6008a8a"
      },
      "outputs": [],
      "source": [
        "DEVICE = torch.device('cuda' if torch.cuda.is_available() else 'cpu')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "id": "35de31fc",
      "metadata": {
        "id": "35de31fc"
      },
      "outputs": [],
      "source": [
        "class TransformerEncoderDecoder(nn.Module):\n",
        "    def __init__(self, vocab_size_enc, vocab_size_dec, embed_dim, num_heads, ff_dim, num_layers, dropout=0.1):\n",
        "        super().__init__()\n",
        "        self.embed_dim = embed_dim\n",
        "        self.num_heads = num_heads\n",
        "        self.embedding_enc = nn.Embedding(vocab_size_enc, embed_dim)\n",
        "        self.embedding_dec = nn.Embedding(vocab_size_dec, embed_dim)\n",
        "        self.positional_encoding = RotaryPositionalEmbeddings(embed_dim // num_heads, max_seq_len=128)\n",
        "\n",
        "        self.transformer = Transformer(\n",
        "            d_model=embed_dim,\n",
        "            nhead=num_heads,\n",
        "            num_encoder_layers=num_layers,\n",
        "            num_decoder_layers=num_layers,\n",
        "            dim_feedforward=ff_dim,\n",
        "            dropout=dropout,\n",
        "            batch_first=True\n",
        "        )\n",
        "\n",
        "        self.output_layer = nn.Linear(embed_dim, vocab_size_dec)\n",
        "\n",
        "    def forward(self, src, tgt, src_key_padding_mask=None, tgt_key_padding_mask=None):\n",
        "\n",
        "        src_embedded = self.embedding_enc(src)\n",
        "        B,S,E = src_embedded.shape\n",
        "        src_embedded = self.positional_encoding(src_embedded.view(B,S,self.num_heads, E//self.num_heads)).view(B,S,E)\n",
        "\n",
        "        tgt_embedded = self.embedding_dec(tgt)\n",
        "        B,S,E = tgt_embedded.shape\n",
        "        tgt_embedded = self.positional_encoding(tgt_embedded.view(B,S,self.num_heads, E//self.num_heads)).view(B,S,E)\n",
        "\n",
        "\n",
        "        tgt_mask = (~torch.tril(torch.ones((S, S), dtype=torch.bool))).to(DEVICE)\n",
        "\n",
        "        encoder_output = self.transformer.encoder(\n",
        "            src_embedded,\n",
        "            src_key_padding_mask=src_key_padding_mask\n",
        "        )\n",
        "\n",
        "        decoder_output = self.transformer.decoder(\n",
        "            tgt_embedded,\n",
        "            encoder_output,\n",
        "            tgt_mask=tgt_mask,\n",
        "            tgt_key_padding_mask=tgt_key_padding_mask,\n",
        "            memory_key_padding_mask=src_key_padding_mask\n",
        "        )\n",
        "\n",
        "        output = self.output_layer(decoder_output)\n",
        "        return output"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 35,
      "id": "f17bebba",
      "metadata": {
        "id": "f17bebba"
      },
      "outputs": [],
      "source": [
        "vocab_size_enc = tokenizer_ru.get_vocab_size()\n",
        "vocab_size_dec = tokenizer_en.get_vocab_size()\n",
        "embed_dim = 36 # еще называется D_MODEL\n",
        "num_heads = 6\n",
        "ff_dim = embed_dim*2 # еще называется D_FF\n",
        "num_layers =4 # количество слоев\n",
        "\n",
        "batch_size = 220\n",
        "\n",
        "model = TransformerEncoderDecoder(vocab_size_enc, vocab_size_dec, embed_dim, num_heads, ff_dim, num_layers)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "id": "6a8dd93d",
      "metadata": {
        "id": "6a8dd93d"
      },
      "outputs": [],
      "source": [
        "training_set = Dataset(X_ru_train, X_en_train)\n",
        "training_generator = torch.utils.data.DataLoader(training_set, batch_size=batch_size, shuffle=True, )\n",
        "\n",
        "valid_set = Dataset(X_ru_valid, X_en_valid)\n",
        "valid_generator = torch.utils.data.DataLoader(valid_set, batch_size=batch_size, shuffle=False)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "id": "2219e7d9",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 447
        },
        "id": "2219e7d9",
        "outputId": "5fee8bd3-b99e-40bc-c54a-c882bf96c7b7"
      },
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "[<matplotlib.lines.Line2D at 0x7c03b209bfd0>]"
            ]
          },
          "metadata": {},
          "execution_count": 20
        },
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ],
      "source": [
        "fake_model = torch.nn.Linear(2, 1)\n",
        "fake_optimizer = torch.optim.AdamW(fake_model.parameters(), lr=0.0001)\n",
        "fake_scheduler = torch.optim.lr_scheduler.OneCycleLR(fake_optimizer, max_lr=0.001, pct_start=0.10,\n",
        "                                                steps_per_epoch=200, epochs=5)\n",
        "lrs = []\n",
        "\n",
        "\n",
        "for i in range(1000):\n",
        "    fake_optimizer.step()\n",
        "    lrs.append(fake_optimizer.param_groups[0][\"lr\"])\n",
        "    fake_scheduler.step()\n",
        "\n",
        "plt.plot(lrs)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 36,
      "id": "d0a1fe41",
      "metadata": {
        "id": "d0a1fe41"
      },
      "outputs": [],
      "source": [
        "model = model.to(DEVICE)\n",
        "loss_fn = torch.nn.CrossEntropyLoss(ignore_index=PAD_IDX).to(DEVICE)\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr=0.0001)\n",
        "\n",
        "NUM_EPOCHS = 5\n",
        "scheduler = torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.001, pct_start=0.05,\n",
        "                                                steps_per_epoch=len(training_generator), epochs=NUM_EPOCHS)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 37,
      "id": "a20cc971",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a20cc971",
        "outputId": "061dbab4-e206-49ad-9a42-8ef5dbdc6631"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Loss: 10.22260643005371;\n",
            "Loss: 10.039559407234192;\n",
            "Loss: 9.764792925516764;\n",
            "Loss: 9.351529883146286;\n",
            "Loss: 8.903454605102539;\n",
            "Loss: 8.551362541516623;\n",
            "Loss: 8.2675864812306;\n",
            "Loss: 8.026660225987435;\n",
            "Loss: 7.820239712397258;\n",
            "Loss: 7.640464460849762;\n",
            "Loss: 7.485070630420338;\n",
            "Loss: 7.348195657730103;\n",
            "Loss: 7.225891337394715;\n",
            "Loss: 7.116971057823726;\n",
            "Loss: 7.018940007527669;\n",
            "Loss: 6.930131225883961;\n",
            "Loss: 6.848825712484472;\n",
            "Loss: 6.774100589222378;\n",
            "Loss: 6.70545385837555;\n",
            "Loss: 6.6417265040874485;\n",
            "Loss: 6.582185973212832;\n",
            "Loss: 6.5268771178072145;\n",
            "Loss: 6.474818596217943;\n",
            "Loss: 6.4267072365681335;\n",
            "Loss: 6.381588676834107;\n",
            "Loss: 6.338934201827416;\n",
            "Loss: 6.298529277201052;\n",
            "Loss: 6.260463747978211;\n",
            "Loss: 6.223842344119631;\n",
            "Loss: 6.189069532394409;\n",
            "Loss: 6.156221886757882;\n",
            "Loss: 6.1248390473425385;\n",
            "Loss: 6.094414660713889;\n",
            "Loss: 6.065417209933786;\n",
            "Loss: 6.0371178490774975;\n",
            "Loss: 6.010218919118246;\n",
            "Loss: 5.984838290987788;\n",
            "Loss: 5.960125498269734;\n",
            "First epoch - 4.957478244304657, saving model..\n",
            "Epoch: 1, Train loss: 5.960, Val loss: 4.957,            Epoch time=556.866s\n",
            "- Hey !\n",
            "You ' re gonna be a little right ?\n",
            "What ' s what you ' re gonna be doing ?\n",
            "I ' m a good of the same - of the same - of the same - of the same - of the Republic of the Republic of the Republic of the Republic\n",
            "Loss: 4.996477093696594;\n",
            "Loss: 4.998662960529328;\n",
            "Loss: 4.997136713663737;\n",
            "Loss: 4.990768536329269;\n",
            "Loss: 4.987317814826965;\n",
            "Loss: 4.981141771475474;\n",
            "Loss: 4.975030479431152;\n",
            "Loss: 4.968065527677536;\n",
            "Loss: 4.963423412640889;\n",
            "Loss: 4.956948480129242;\n",
            "Loss: 4.9521533688631925;\n",
            "Loss: 4.9466575102011365;\n",
            "Loss: 4.941646665793199;\n",
            "Loss: 4.937054239681789;\n",
            "Loss: 4.933781974474589;\n",
            "Loss: 4.929329298734665;\n",
            "Loss: 4.92462946471046;\n",
            "Loss: 4.920727811654409;\n",
            "Loss: 4.915771231149372;\n",
            "Loss: 4.911004773378372;\n",
            "Loss: 4.906251210485186;\n",
            "Loss: 4.9024846692518755;\n",
            "Loss: 4.898432217266248;\n",
            "Loss: 4.894624913732211;\n",
            "Loss: 4.891164201927185;\n",
            "Loss: 4.887317687914922;\n",
            "Loss: 4.88307890786065;\n",
            "Loss: 4.878523725271225;\n",
            "Loss: 4.875446920888177;\n",
            "Loss: 4.871941564083099;\n",
            "Loss: 4.868185295751018;\n",
            "Loss: 4.86435610845685;\n",
            "Loss: 4.860785445589007;\n",
            "Loss: 4.856891227609971;\n",
            "Loss: 4.853480126108442;\n",
            "Loss: 4.850023030969831;\n",
            "Loss: 4.846299713753365;\n",
            "Loss: 4.842779637010474;\n",
            "Improved from 4.957478244304657 to 4.626512978076935, saving model..\n",
            "Epoch: 2, Train loss: 4.843, Val loss: 4.627,            Epoch time=557.241s\n",
            "- Oh !\n",
            "You ' re going to me ?\n",
            "What are you doing ?\n",
            "I ' m a good .\n",
            "Loss: 4.694839811325073;\n",
            "Loss: 4.694829585552216;\n",
            "Loss: 4.690870480537415;\n",
            "Loss: 4.6890638172626495;\n",
            "Loss: 4.687166527748108;\n",
            "Loss: 4.6856223599116005;\n",
            "Loss: 4.68325217791966;\n",
            "Loss: 4.680480290651321;\n",
            "Loss: 4.67518751250373;\n",
            "Loss: 4.672518842697143;\n",
            "Loss: 4.670886679129167;\n",
            "Loss: 4.669201976458232;\n",
            "Loss: 4.665959112827594;\n",
            "Loss: 4.663862671511514;\n",
            "Loss: 4.661699312527975;\n",
            "Loss: 4.659991645216942;\n",
            "Loss: 4.658032969026005;\n",
            "Loss: 4.6558159719573124;\n",
            "Loss: 4.6537397683294195;\n",
            "Loss: 4.651919951915741;\n",
            "Loss: 4.650305505934216;\n",
            "Loss: 4.648448778282512;\n",
            "Loss: 4.6469970618123595;\n",
            "Loss: 4.64576083679994;\n",
            "Loss: 4.643834828948974;\n",
            "Loss: 4.642819592219133;\n",
            "Loss: 4.641556019606414;\n",
            "Loss: 4.6398916448865615;\n",
            "Loss: 4.639153845392425;\n",
            "Loss: 4.637965853214264;\n",
            "Loss: 4.636394740381548;\n",
            "Loss: 4.635263071656227;\n",
            "Loss: 4.633580178925485;\n",
            "Loss: 4.632547562122345;\n",
            "Loss: 4.631390255791801;\n",
            "Loss: 4.629629365470675;\n",
            "Loss: 4.628380178503088;\n",
            "Loss: 4.627158824895558;\n",
            "Improved from 4.626512978076935 to 4.493264808654785, saving model..\n",
            "Epoch: 3, Train loss: 4.627, Val loss: 4.493,            Epoch time=556.387s\n",
            "Morning !\n",
            "You ' re going to me ?\n",
            "What are you doing ?\n",
            "I ' m a little bit of the world .\n",
            "Loss: 4.559172677993774;\n",
            "Loss: 4.552411777973175;\n",
            "Loss: 4.554955237706502;\n",
            "Loss: 4.552614119052887;\n",
            "Loss: 4.5530187044143675;\n",
            "Loss: 4.552005758285523;\n",
            "Loss: 4.552704068592616;\n",
            "Loss: 4.55114674448967;\n",
            "Loss: 4.549943788316515;\n",
            "Loss: 4.549036734104156;\n",
            "Loss: 4.548653184283864;\n",
            "Loss: 4.5471820100148514;\n",
            "Loss: 4.545252779447115;\n",
            "Loss: 4.544834782055446;\n",
            "Loss: 4.542910257657369;\n",
            "Loss: 4.543273909389972;\n",
            "Loss: 4.543806801964255;\n",
            "Loss: 4.543612594339582;\n",
            "Loss: 4.542965363703276;\n",
            "Loss: 4.542407430171966;\n",
            "Loss: 4.542443854014079;\n",
            "Loss: 4.542255054603923;\n",
            "Loss: 4.541098123840664;\n",
            "Loss: 4.540050726731618;\n",
            "Loss: 4.5399014158248905;\n",
            "Loss: 4.538864766451029;\n",
            "Loss: 4.538590965270996;\n",
            "Loss: 4.537487724508558;\n",
            "Loss: 4.536965865760014;\n",
            "Loss: 4.536392505963644;\n",
            "Loss: 4.536068443021467;\n",
            "Loss: 4.5352705523371695;\n",
            "Loss: 4.534440715096213;\n",
            "Loss: 4.53314987449085;\n",
            "Loss: 4.532547509057181;\n",
            "Loss: 4.531971901257833;\n",
            "Loss: 4.531648709838454;\n",
            "Loss: 4.530775127536372;\n",
            "Improved from 4.493264808654785 to 4.439868593215943, saving model..\n",
            "Epoch: 4, Train loss: 4.531, Val loss: 4.440,            Epoch time=556.776s\n",
            "Morning !\n",
            "You ' re going to me ?\n",
            "What are you doing ?\n",
            "I ' m a good .\n",
            "Loss: 4.496519093513489;\n",
            "Loss: 4.492638411521912;\n",
            "Loss: 4.484805607795716;\n",
            "Loss: 4.486462531089782;\n",
            "Loss: 4.487092722892761;\n",
            "Loss: 4.487150922616323;\n",
            "Loss: 4.489801679338727;\n",
            "Loss: 4.490507780909538;\n",
            "Loss: 4.490058455997043;\n",
            "Loss: 4.492310544013977;\n",
            "Loss: 4.492804353887385;\n",
            "Loss: 4.492589345375697;\n",
            "Loss: 4.4925498830355135;\n",
            "Loss: 4.493525411060878;\n",
            "Loss: 4.493392558733622;\n",
            "Loss: 4.493510431051254;\n",
            "Loss: 4.494397666594561;\n",
            "Loss: 4.494312973022461;\n",
            "Loss: 4.493884721555208;\n",
            "Loss: 4.493759376287461;\n",
            "Loss: 4.493455511047727;\n",
            "Loss: 4.493108222701332;\n",
            "Loss: 4.493080638180609;\n",
            "Loss: 4.493081646164258;\n",
            "Loss: 4.493144111824035;\n",
            "Loss: 4.4933700944827155;\n",
            "Loss: 4.49302096384543;\n",
            "Loss: 4.4932235295431955;\n",
            "Loss: 4.493115427740689;\n",
            "Loss: 4.493690917174021;\n",
            "Loss: 4.493335441927756;\n",
            "Loss: 4.493724402338266;\n",
            "Loss: 4.493989532066114;\n",
            "Loss: 4.493976687964271;\n",
            "Loss: 4.494530952317374;\n",
            "Loss: 4.49431584821807;\n",
            "Loss: 4.4939862859571305;\n",
            "Loss: 4.494264308904347;\n",
            "Improved from 4.439868593215943 to 4.431376991271972, saving model..\n",
            "Epoch: 5, Train loss: 4.494, Val loss: 4.431,            Epoch time=557.079s\n",
            "Morning !\n",
            "You ' re gonna get me ?\n",
            "What are you doing ?\n",
            "I ' m a little bit of the world .\n"
          ]
        }
      ],
      "source": [
        "from timeit import default_timer as timer\n",
        "\n",
        "losses = []\n",
        "run = None\n",
        "\n",
        "for epoch in range(1, NUM_EPOCHS+1):\n",
        "    start_time = timer()\n",
        "    train_loss = train(model, training_generator, optimizer, loss_fn, scheduler, run)\n",
        "    end_time = timer()\n",
        "    val_loss = evaluate(model, valid_generator, loss_fn, run)\n",
        "\n",
        "    if not losses:\n",
        "        print(f'First epoch - {val_loss}, saving model..')\n",
        "        torch.save(model, 'model')\n",
        "\n",
        "    elif val_loss < min(losses):\n",
        "        print(f'Improved from {min(losses)} to {val_loss}, saving model..')\n",
        "        torch.save(model, 'model')\n",
        "\n",
        "    losses.append(val_loss)\n",
        "\n",
        "    print((f\"Epoch: {epoch}, Train loss: {train_loss:.3f}, Val loss: {val_loss:.3f}, \\\n",
        "           \"f\"Epoch time={(end_time-start_time):.3f}s\"))\n",
        "\n",
        "    print(translate(\"Доброе утро!\"))\n",
        "    print(translate('Ты можешь купить мне кофе?'))\n",
        "    print(translate('Что ты собираешься сделать с книгой?'))\n",
        "    print(translate('Я часто вижу арбузы во сне'))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 39,
      "id": "e8f35e4e",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "e8f35e4e",
        "outputId": "9d04804e-9c7e-4a89-a116-ec3d4b732d82"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 4-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 2-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n",
            "/usr/local/lib/python3.11/dist-packages/nltk/translate/bleu_score.py:577: UserWarning: \n",
            "The hypothesis contains 0 counts of 3-gram overlaps.\n",
            "Therefore the BLEU score evaluates to 0, independently of\n",
            "how many N-gram overlaps of lower order it contains.\n",
            "Consider using lower n-gram order or use SmoothingFunction()\n",
            "  warnings.warn(_msg)\n"
          ]
        }
      ],
      "source": [
        "import nltk\n",
        "\n",
        "hypothesis_d = ru_sents[300:420]\n",
        "reference_d = en_sents[300:420]\n",
        "\n",
        "\n",
        "hypotheses = []\n",
        "for hyp in hypothesis_d:\n",
        "  hypotheses.append(translate(hyp))\n",
        "\n",
        "bleus = {}\n",
        "\n",
        "for i, hyp in enumerate(hypotheses):\n",
        "    reference = reference_d[i].split()\n",
        "    hypothesis_sp = hyp.split()\n",
        "    refohyp = (reference_d[i], hyp)\n",
        "    bleus[refohyp] = nltk.translate.bleu_score.sentence_bleu([reference], hypothesis_sp, auto_reweigh=True)\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 40,
      "id": "37e154e2",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "37e154e2",
        "outputId": "dc7f608b-aff1-44c4-e2a1-0b82b0be0142"
      },
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[(('The time now is 11:55 AM .', 'The time now is 07 : 51 PM .'), 0.3155984539112945), (('I... I think I should.', \"I think I ' m sorry .\"), 5.021333847570327e-78), (('Thank you very much.', 'Thank you .'), 1.3973640466737633e-103), (('- Good night.', '- Good night .'), 9.53091075863908e-155), (('- How you doing?', '- How do you know ?'), 8.38826642100846e-155)]\n"
          ]
        }
      ],
      "source": [
        "res = sorted(bleus.items(), key=lambda item: item[1], reverse=True)[:5]\n",
        "print(res)"
      ]
    },
    {
      "cell_type": "markdown",
      "id": "b5aa93d6",
      "metadata": {
        "id": "b5aa93d6"
      },
      "source": [
        "\n",
        "## Задание 2 (2 балла).\n",
        "Прочитайте главу про машинный перевод у Журафски и Маннига - https://web.stanford.edu/~jurafsky/slp3/13.pdf\n",
        "Ответьте своими словами в чем заключается техника back translation? Для чего она применяется и что позволяет получить? Опишите по шагам как ее применить к паре en->ru на данных из семинара. Сколько моделей понадобится? Сколько запусков обучения нужно будет сделать?\n",
        "\n",
        "Ответ должен содержать как минимум 10 предложений."
      ]
    },
    {
      "cell_type": "markdown",
      "id": "ca159358",
      "metadata": {
        "id": "ca159358"
      },
      "source": [
        "Back translation - частный случай аугментации данных, статистического метода искусственной генерации новых даных на основе существующих. Суть данной техники заключается в том, что хотя часто параллельные корпуса для некоторых языков небольшие и ограниченные, мы нередко можем обратиться к большому, ну или хотя бы более крупному, чем параллельный корпус, одноязычному корпусу. И данные из этого корпуса мы можем добавить к параллельным корпусам.\n",
        "Цель back translation - улучшить машинный перевод при помощи небольшого параллельного корпуса с исходным (source) и целевым (target) языками и с помощью корпуса с целевым языком.\n",
        "Для начала нужно использовать паралелльные тексты, чтобы обучить модель перевода в обратном порядке. В нашем случае, для пары en -> ru мы будем обучать модель на паре ru -> en. Далее полученную модель мы используем для перевода одноязычного корпуса текстов на целевом языке (русский) на исходный (английский). Таким образом, мы получаем параллельный текст. Его мы добавим в тренировочный сет и обучим модель перевода с исходного языка на целевой (с английского на русского).\n",
        "В итоге, мы получим 2 модели, и нам понадобится 2 запуска обучения."
      ]
    }
  ],
  "metadata": {
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.16"
    },
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "accelerator": "GPU"
  },
  "nbformat": 4,
  "nbformat_minor": 5
}