{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "371970ff",
   "metadata": {},
   "source": [
    "# Домашнее задание № 3. Исправление опечаток"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b35cf8bd",
   "metadata": {},
   "source": [
    "## 1. Доп. ранжирование по вероятности (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0c6be25c",
   "metadata": {},
   "source": [
    "Дополните get_closest_hybrid_match в семинаре так, чтобы из кандадатов с одинаковым расстоянием редактирования выбиралось наиболее вероятное."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 233,
   "id": "c63dc62c",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, re\n",
    "from string import punctuation\n",
    "import numpy as np\n",
    "import json\n",
    "from collections import Counter\n",
    "from pprint import pprint\n",
    "from nltk import sent_tokenize\n",
    "punctuation += \"«»—…“”\"\n",
    "punct = set(punctuation)\n",
    "from sklearn.metrics import classification_report, accuracy_score\n",
    "from string import punctuation\n",
    "from razdel import sentenize\n",
    "from razdel import tokenize as razdel_tokenize\n",
    "import numpy as np\n",
    "from collections import Counter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 232,
   "id": "e3c13c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "from sklearn.metrics.pairwise import cosine_similarity, cosine_distances"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 234,
   "id": "457b2f55",
   "metadata": {},
   "outputs": [],
   "source": [
    "import textdistance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 235,
   "id": "4b0a1e85",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tqdm import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 236,
   "id": "e98e3437",
   "metadata": {},
   "outputs": [],
   "source": [
    "from difflib import get_close_matches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 239,
   "id": "b23febf7",
   "metadata": {},
   "outputs": [],
   "source": [
    "word2id = list(vocab.keys())\n",
    "id2word = {i:word for i, word in enumerate(vocab)}\n",
    "\n",
    "\n",
    "vec = CountVectorizer(analyzer='char', max_features=10000, ngram_range=(1,3))\n",
    "X = vec.fit_transform(vocab)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 240,
   "id": "706f805f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_match_vec(text, X, vec, topn=20):\n",
    "    v = vec.transform([text])\n",
    "    similarities = cosine_distances(v, X)[0]\n",
    "    topn = similarities.argsort()[:topn] \n",
    "    \n",
    "    return [(id2word[top], similarities[top]) for top in topn]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 241,
   "id": "f8e8814a",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_match_with_metric(text, lookup,topn=20, metric=textdistance.levenshtein):\n",
    "    # Counter можно использовать и с не целыми числами\n",
    "    similarities = Counter()\n",
    "    \n",
    "    for word in lookup:\n",
    "        similarities[word] = metric.normalized_similarity(text, word) \n",
    "    \n",
    "    return similarities.most_common(topn)\n",
    "\n",
    "def get_closest_hybrid_match(text, X, vec, topn=3, metric=textdistance.damerau_levenshtein):\n",
    "    candidates = get_closest_match_vec(text, X, vec, topn*4)\n",
    "    lookup = [cand[0] for cand in candidates]\n",
    "    closest = get_closest_match_with_metric(text, lookup, topn, metric=metric)\n",
    "\n",
    "    \n",
    "    return closest\n",
    "\n",
    "N = sum(vocab.values())\n",
    "\n",
    "def P(word, N=N):\n",
    "    return vocab[word] / N\n",
    "\n",
    "def predict_mistaken(word, vocab):\n",
    "    return 0 if word in vocab else 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 237,
   "id": "e67f8d02",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = open('data/wiki_data.txt', encoding='utf8').read()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 238,
   "id": "0c739c56",
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = Counter(re.findall(r'\\w+', corpus.lower()))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "524a01bf",
   "metadata": {},
   "source": [
    "Код"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bf56a1e3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_closest_hybrid_match(text, X, vec, topn=3, metric=textdistance.damerau_levenshtein):\n",
    "    candidates = get_closest_match_vec(text, X, vec, topn*4)\n",
    "    lookup = [cand[0] for cand in candidates]\n",
    "    closest = get_closest_match_with_metric(text, lookup, topn, metric=metric)\n",
    "    closest = dict(closest)\n",
    "    p = {}\n",
    "    # all = []\n",
    "    for key, val in closest.items():\n",
    "        p[key] = [val, P(key)]\n",
    "    res = sorted(p.items(), key=lambda x: x[1][1], reverse=True)   \n",
    "     \n",
    "    # for val in p.values():\n",
    "    #     all.append(val[1])\n",
    "    #num = max(all)    \n",
    "    # for k, v in p.items():\n",
    "    #     if v[1] == num:\n",
    "    #         return k, v\n",
    "    # а здесь до меня дошло исп. min и max и я прозрела и поплакала из-за потерянного времени, ведь я все это время смотрела только на цифру перед точкой\n",
    "    return res[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 479,
   "id": "a87813ac",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "('папоротник', [0.9, 1.9397592254463824e-06])"
      ]
     },
     "execution_count": 479,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_hybrid_match(\"папородник\", X, vec)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 474,
   "id": "f52cd8a5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('бизнес', [0.8333333333333334, 3.278193091004386e-05]),\n",
       " ('бизнеса', [0.7142857142857143, 2.4634942163169054e-05]),\n",
       " ('бизнесе', [0.7142857142857143, 5.431325831249871e-06])]"
      ]
     },
     "execution_count": 474,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "get_closest_hybrid_match(\"бизнез\", X, vec)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f9cf9985",
   "metadata": {},
   "source": [
    "## 2.  Symspell (7 баллов)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9392cc23",
   "metadata": {},
   "source": [
    "Реализуйте алгоритм Symspell. Он похож на алгоритм Норвига, но проще и быстрее. Он основан только на одной операции - удалении символа. Описание алгоритма по шагам:\n",
    "\n",
    "1) Составляется словарь правильных слов  \n",
    "2) На основе словаря правильных слов составляется словарь удалений - для каждого правильного слова создаются все варианты удалений и создается словарь, где ключ - слово с удалением, а значение - правильное слово  (!) \n",
    "3) Для выбора исправления для слова с опечаткой генерируются все варианты удаления, из них выбираются те, что есть в словаре удалений, построенного на шаге 2. Слово с опечаткой заменяется на правильное слово, соответствующее варианту удаления  \n",
    "4) Если в словаре удалений есть несколько вариантов, то выбирается удаление, которому соответствует наиболее вероятное правильное слово  \n",
    "\n",
    "\n",
    "Оцените качество полученного алгоритма теми же тремя метриками."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 242,
   "id": "96b7eca0",
   "metadata": {},
   "outputs": [],
   "source": [
    "# составляем словарь правильных слов (шаг 1)\n",
    "correct_sents = open('data/correct_sents.txt', encoding='utf8').read()\n",
    "vocab_cs = re.findall(r'\\w+', correct_sents.lower())\n",
    "correct_words = dict(zip(vocab_cs, [P(word) for word in vocab_cs])) #с вероятностью\n",
    "# wiki\n",
    "vocab = Counter(re.findall(r'\\w+', corpus.lower()))\n",
    "vocab_withp = dict(zip(vocab.keys(), [P(word) for word in vocab.keys()]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 243,
   "id": "a2df5c96",
   "metadata": {},
   "outputs": [],
   "source": [
    "bad = open('data/sents_with_mistakes.txt', encoding='utf8').read().splitlines()\n",
    "true = open('data/correct_sents.txt', encoding='utf8').read().splitlines()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 244,
   "id": "9bfa8d2c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# удаляем по 1 букве в слове\n",
    "def get_delete(word):\n",
    "    splits     = [(word[:i], word[i:])    for i in range(len(word) + 1)]\n",
    "    deletes    = [L + R[1:]               for L, R in splits if R]\n",
    "    return deletes\n",
    "\n",
    "\n",
    "# составляем словарь удалений (шаг 2)\n",
    "del_dict = {}\n",
    "for word in correct_words.keys():\n",
    "    w = get_delete(word)\n",
    "    for i in w:\n",
    "        if i in del_dict.keys():\n",
    "            del_dict[i].append(word)\n",
    "        else:\n",
    "            del_dict[i]=[word]\n",
    "\n",
    "another_dd = {}\n",
    "for word in vocab_withp.keys():\n",
    "    w = get_delete(word)\n",
    "    for i in w:\n",
    "        if i in another_dd.keys():\n",
    "            another_dd[i].append(word)\n",
    "        else:\n",
    "            another_dd[i]=[word]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 245,
   "id": "ce451554",
   "metadata": {},
   "outputs": [],
   "source": [
    "# на вход подается слово с ошибкой, в нем удаляется по букве,\n",
    "# и если какие-то варианты есть в словаре, они выводятся списком\n",
    "def del_inc(incorrect_word):\n",
    "    variants = get_delete(incorrect_word)\n",
    "    return [i for i in variants if i in del_dict.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 246,
   "id": "79bbf494",
   "metadata": {},
   "outputs": [],
   "source": [
    "# шаги 3 и 4\n",
    "def get_correction(incorrect_word):\n",
    "    correct = del_inc(incorrect_word)\n",
    "    if len(correct) == 0:\n",
    "        return incorrect_word\n",
    "    else:\n",
    "        # в список добавляются все слова из словаря, в которых содерж. то, что в correct\n",
    "        words = []\n",
    "        for i in correct:\n",
    "            words += del_dict[i]\n",
    "            words = list(tuple(words))\n",
    "        # составляем словарь с вариантами и их вероятностями  \n",
    "        variants = {}\n",
    "        for i in words:\n",
    "            variants[i] = correct_words[i]\n",
    "        result = sorted(variants.items(), key=lambda x:x [1], reverse = True) \n",
    "        return result\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 247,
   "id": "27f0f0cc",
   "metadata": {},
   "outputs": [],
   "source": [
    "def align_words(sent_1, sent_2):\n",
    "    tokens_1 = sent_1.lower().split()\n",
    "    tokens_2 = sent_2.lower().split()\n",
    "    \n",
    "    tokens_1 = [token.strip(punctuation) for token in tokens_1]\n",
    "    tokens_2 = [token.strip(punctuation) for token in tokens_2]\n",
    "    \n",
    "    tokens_1 = [token for token in tokens_1 if token]\n",
    "    tokens_2 = [token for token in tokens_2 if token]\n",
    "    \n",
    "    assert len(tokens_1) == len(tokens_2)\n",
    "    \n",
    "    return list(zip(tokens_1, tokens_2))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 248,
   "id": "a9e2f195",
   "metadata": {},
   "outputs": [],
   "source": [
    "def predict_mistaken(word, vocab):\n",
    "    return 0 if word in vocab else 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 249,
   "id": "0a9c5163",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 915/915 [00:00<00:00, 1293.04it/s]\n"
     ]
    }
   ],
   "source": [
    "# метрики\n",
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_mistaken = 0\n",
    "mistaken_fixed = 0\n",
    "\n",
    "total_correct = 0\n",
    "correct_broken = 0\n",
    "mistakes = []\n",
    "cashed = {}\n",
    "for i in tqdm(range(len(true))):\n",
    "    word_pairs = align_words(true[i], bad[i])\n",
    "    for pair in word_pairs:\n",
    "        if predict_mistaken(pair[1], vocab_cs):\n",
    "            predicted = cashed.get(pair[1], get_correction(pair[1])[0][0])\n",
    "            cashed[pair[1]] = predicted\n",
    "        else:\n",
    "            predicted = pair[1]\n",
    "        \n",
    "        if predicted == pair[0]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            mistakes.append((pair[0], pair[1], predicted))\n",
    "        total += 1\n",
    "        \n",
    "        if pair[0] == pair[1]:\n",
    "            total_correct += 1\n",
    "            if pair[0] !=  predicted:\n",
    "                correct_broken += 1\n",
    "        else:\n",
    "            total_mistaken += 1\n",
    "            if pair[0] == predicted:\n",
    "                mistaken_fixed += 1\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 250,
   "id": "1ad67745",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8987493746873437\n",
      "0.2857142857142857\n",
      "0.01056621109452165\n"
     ]
    }
   ],
   "source": [
    "print(correct/total)\n",
    "print(mistaken_fixed/total_mistaken)\n",
    "print(correct_broken/total_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 254,
   "id": "247aa2a8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def del_inc2(incorrect_word):\n",
    "    variants = get_delete(incorrect_word)\n",
    "    return [i for i in variants if i in another_dd.keys()]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 255,
   "id": "6357daa9",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_correction2(incorrect_word):\n",
    "    correct = del_inc2(incorrect_word)\n",
    "    if len(correct) == 0:\n",
    "        return incorrect_word\n",
    "    else:\n",
    "        # в список добавляются все слова из словаря, в которых содерж. то, что в correct\n",
    "        words = []\n",
    "        for i in correct:\n",
    "            words += another_dd[i]\n",
    "            words = list(tuple(words))\n",
    "        # составляем словарь с вариантами и их вероятностями  \n",
    "        variants = {}\n",
    "        for i in words:\n",
    "            variants[i] = vocab_withp[i]\n",
    "        result = sorted(variants.items(), key=lambda x:x [1], reverse = True) \n",
    "        return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 257,
   "id": "7f3e5e4a",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "100%|██████████| 915/915 [00:00<00:00, 933.32it/s] \n"
     ]
    }
   ],
   "source": [
    "correct = 0\n",
    "total = 0\n",
    "\n",
    "total_mistaken = 0\n",
    "mistaken_fixed = 0\n",
    "\n",
    "total_correct = 0\n",
    "correct_broken = 0\n",
    "mistakes = []\n",
    "cashed = {}\n",
    "for i in tqdm(range(len(true))):\n",
    "    word_pairs = align_words(true[i], bad[i])\n",
    "    for pair in word_pairs:\n",
    "        if predict_mistaken(pair[1], vocab_cs):\n",
    "            predicted = cashed.get(pair[1], get_correction2(pair[1])[0][0])\n",
    "            cashed[pair[1]] = predicted\n",
    "        else:\n",
    "            predicted = pair[1]\n",
    "        \n",
    "        if predicted == pair[0]:\n",
    "            correct += 1\n",
    "        else:\n",
    "            mistakes.append((pair[0], pair[1], predicted))\n",
    "        total += 1\n",
    "        \n",
    "        if pair[0] == pair[1]:\n",
    "            total_correct += 1\n",
    "            if pair[0] !=  predicted:\n",
    "                correct_broken += 1\n",
    "        else:\n",
    "            total_mistaken += 1\n",
    "            if pair[0] == predicted:\n",
    "                mistaken_fixed += 1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 258,
   "id": "75e856ae",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.8890445222611305\n",
      "0.21040372670807453\n",
      "0.01056621109452165\n"
     ]
    }
   ],
   "source": [
    "print(correct/total)\n",
    "print(mistaken_fixed/total_mistaken)\n",
    "print(correct_broken/total_correct)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bea4a597",
   "metadata": {},
   "outputs": [],
   "source": [
    "# words = []\n",
    "# for word in vocab:\n",
    "#     words.append(word) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "00edbfe5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# dict_delets = {}\n",
    "# def make_dict(word):\n",
    "#     deletions = []\n",
    "#     deletions = (get_delete(word))\n",
    "#     for delete in deletions:\n",
    "#         if delete not in dict_delets.keys():\n",
    "#             dict_delets[delete] = [word]\n",
    "#         else:\n",
    "#             dict_delets[delete].append(word)\n",
    "#     return dict_delets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "9f7e3a66",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'от': ['кот'],\n",
       " 'кт': ['кот'],\n",
       " 'ко': ['кот', 'код'],\n",
       " 'од': ['код'],\n",
       " 'кд': ['код']}"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# make_dict('код')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cf602164",
   "metadata": {},
   "outputs": [],
   "source": [
    "# # составляем словарь удалений (шаг 2)\n",
    "# v = {}\n",
    "# for word in vocab_withp.keys():\n",
    "#     w = get_delete(word)\n",
    "#     for i in w:\n",
    "#         if i in v.keys():\n",
    "#             v[i].append(word)\n",
    "#         else:\n",
    "#             v[i]=[word]\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "barbiturat",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
